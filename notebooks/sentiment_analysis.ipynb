{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avinash-Amudala/InsightNews-ISTE612/blob/sp4300/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elvLpKmJwNOS"
      },
      "outputs": [],
      "source": [
        "%pip install transformers==4.41.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install matplotlib\n",
        "%pip install pyplot\n",
        "%pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "import json\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def print_encoding(model_inputs, indent=4):\n",
        "    indent_str = \" \" * indent \n",
        "    print(\"{\")\n",
        "    for k,v in model_inputs.items():\n",
        "        print(indent_str + k + \":\")\n",
        "        print(indent_str + indent_str + str(v))\n",
        "    print(\"}\")\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/shreyasimac/Desktop/projects/InsightNews-ISTE612/notebooks'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# /Users/shreyasimac/Desktop/projects/InsightNews-ISTE612/data/processed/articles_cleaned.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['source', 'author', 'title', 'description', 'url', 'urlToImage', 'publishedAt', 'content', 'topic', 'content_length']\n",
            "Tokenized train dataset columns: ['source', 'author', 'title', 'description', 'url', 'urlToImage', 'publishedAt', 'content', 'topic', 'content_length', 'labels']\n",
            "Tokenized test dataset columns: ['source', 'author', 'title', 'description', 'url', 'urlToImage', 'publishedAt', 'content', 'topic', 'content_length', 'labels']\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load your dataset\n",
        "data = load_dataset('csv', data_files='/Users/shreyasimac/Desktop/projects/InsightNews-ISTE612/data/processed/articles_cleaned.csv')\n",
        "\n",
        "# Inspect the dataset to find the correct column name\n",
        "print(data['train'].column_names)\n",
        "\n",
        "# Create labels if not present\n",
        "def create_labels(example):\n",
        "    label_mapping = {'positive': 1, 'negative': 0}  # Adjust according to your labels\n",
        "    example['labels'] = label_mapping.get(example['topic'], -1)  # Assuming 'topic' column has sentiment labels\n",
        "    return example\n",
        "\n",
        "# Apply the function to create labels\n",
        "data = data.map(create_labels)\n",
        "\n",
        "# Filter out examples with invalid labels (e.g., label = -1)\n",
        "data = data.filter(lambda x: x['labels'] != -1)\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_test_split = data['train'].train_test_split(test_size=0.2)\n",
        "train_dataset = train_test_split['train']\n",
        "test_dataset = train_test_split['test']\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('siebert/sentiment-roberta-large-english')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('siebert/sentiment-roberta-large-english')\n",
        "\n",
        "# Tokenize the data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['content'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Apply the tokenization function\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Inspect the tokenized datasets\n",
        "print(\"Tokenized train dataset columns:\", tokenized_train.column_names)\n",
        "print(\"Tokenized test dataset columns:\", tokenized_test.column_names)\n",
        "\n",
        "\n",
        "# Define training arguments\n",
        "\n",
        "\n",
        "# Initialize the Trainer\n",
        "\n",
        "\n",
        "# Train the model\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP6hoddzXqJibcRmTAOGBuX",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
